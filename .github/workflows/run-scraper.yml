name: Run Scraper

on:
  workflow_dispatch:   # Manual trigger via GitHub UI
  push:                # Automatically runs on code push

jobs:
  run-scraper-job:
    runs-on: ubuntu-latest
    timeout-minutes: 360  # â± Max timeout = 6 hours

    steps:
      - name: ğŸ“¥ Checkout Repository
        uses: actions/checkout@v4

      - name: ğŸ Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: ğŸ§© Install Chrome (v124) and Chromedriver (v124)
        run: |
          sudo apt update
          sudo apt install -y wget unzip curl gnupg libglib2.0-0 libnss3 libxss1 \
            libatk-bridge2.0-0 libgtk-3-0 libu2f-udev libvulkan1 libxi6 libxtst6 \
            fonts-liberation xdg-utils
          
          # Install Chrome
          wget https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/124.0.6367.91/linux64/chrome-linux64.zip
          unzip chrome-linux64.zip
          sudo mv chrome-linux64 /opt/google
          sudo ln -sf /opt/google/chrome-linux64/chrome /usr/bin/google-chrome
          
          # Install Chromedriver
          wget https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/124.0.6367.91/linux64/chromedriver-linux64.zip
          unzip chromedriver-linux64.zip
          sudo mv chromedriver-linux64/chromedriver /usr/local/bin/
          sudo chmod +x /usr/local/bin/chromedriver

      - name: ğŸ“¦ Install Python Requirements
        run: |
          pip install --no-cache-dir -r requirements.txt

      - name: â± Start Keep-Alive Background Process
        run: |
          (while true; do echo "â³ Still running..."; sleep 300; done) &
          echo $! > keepalive.pid

      - name: â–¶ï¸ Run Scraper
        run: python scraper.py

      - name: ğŸ›‘ Stop Keep-Alive Process
        if: always()
        run: |
          if [ -f keepalive.pid ]; then
            kill $(cat keepalive.pid) || true
            rm keepalive.pid
          fi

      - name: ğŸ“¤ Upload Scraped CSV
        uses: actions/upload-artifact@v4
        with:
          name: scraped-csv
          path: allcorectpricees.csv
